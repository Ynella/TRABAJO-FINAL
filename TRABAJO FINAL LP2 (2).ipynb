{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### IMPORTANTE #################################\n",
    "\n",
    "# SE NECESITA CONFIGURAR COMO AREA DE TRABAJO LA CARPETA QUE CONTIENE EL EXCEL VACIO Y EL CÓDIGO \n",
    "# (AMBOS EN LA MISMA CARPETA)\n",
    "\n",
    "import os\n",
    "os.chdir(\"C:/Users/flavi/OneDrive/Desktop/estasi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # importa la libreria Beautifulsoup\n",
    "import requests               # importa libreria requests\n",
    "import pandas as pd           # importa la libreria pandas\n",
    "import openpyxl               # importa la libreria openpyxl\n",
    "\n",
    "archivo_excel_vacio = pd.read_excel(\"TablaVacia.xlsx\",header=1,index_col=0) # leer excel de cabecera fila 1 y indice columna 0\n",
    "lista_genes_abreviados=list(archivo_excel_vacio[\"GEN ABREV\"]) # importamos la columna que tiene los genes abreviados y los introducimos a una lista\n",
    "m=3  # se incia en la fila 3\n",
    "for i in lista_genes_abreviados: # lee cada abreviación del gen\n",
    "    URL=f\"https://www.uniprot.org/uniprot/?query={i.upper()}+bos+taurus&sort=score\" # introducimos el url de busqueda de la pagina requerida\n",
    "    page=requests.get(URL) # conección a la pagina\n",
    "    soup=BeautifulSoup(page.content,\"html.parser\") # almacena el codigo html\n",
    "\n",
    "    link_entry=soup.find_all(\"td\",class_=\"entryID\") # lista de entradas que aparacen en el resultado de la busqueda\n",
    "    indice=[]  # genera una lista vacia\n",
    "    for P in link_entry: # para cada entrada que aparece en el resultado de busqueda se almacena en la lista indice\n",
    "        indice.append(P.text) # añade los resultados a la lista vacia\n",
    "    try:  # si hay un resultado en el indice va intentar ejecutar el siguiente codigo\n",
    "        FINAL=indice[0]   # selecciona el primer resultado\n",
    "        url=f\"https://www.uniprot.org/uniprot/{FINAL}\" # introduce el url del primer resultado\n",
    "        page=requests.get(url)  # conección a la pagina\n",
    "        soup=BeautifulSoup(page.content,\"html.parser\") # almacena el codigo html\n",
    "               \n",
    "        #ENTRY Y ENTRY NAME\n",
    "        entry_name=soup.find_all(\"h2\",class_=\"page-title\") # busca todos los elementos que tengan etiqueta h2 \n",
    "        for Q in entry_name: # limpia los resultados y extrae unicamente los textos\n",
    "            entry1=Q.text # extrae unicamente los textos\n",
    "        entry1=entry1.split() # extrae unicamente los textos\n",
    "        ENTRY=entry1[2] # selecciona el elemento número 2 de los textos\n",
    "        ENTRY_NAME=\"\".join(list(entry1[3])[1:len(list(entry1[3]))-1]) # introduce lo encontrado anteriormente y lo selecciona como entry_name\n",
    "\n",
    "        #PROTEINA\n",
    "        protein=soup.find_all(\"h1\",property=\"name\") # busca todos los elementos que tenga etiqueta h1\n",
    "        for Q in protein:  # limpia los resultados \n",
    "            PROTEIN=Q.text # extrae unicamente los textos\n",
    "\n",
    "        #GEN\n",
    "        gen_abrev=soup.find_all(\"div\",class_='entry-overview-content',id=\"content-gene\") # busca todos los elementos que contienen id \"content-gene\", con etiqueta div.\n",
    "        for Q in gen_abrev: # limpia los resultados\n",
    "            GEN_ABREV=Q.text # extrae unicamente los textos\n",
    "\n",
    "        #ORGANISMO\n",
    "        organismo=soup.find_all(\"div\",class_='entry-overview-content',id=\"content-organism\") # busca todos los elementos que contienen id \"content-organism\", con etiqueta div.\n",
    "        for Q in organismo: # limpia los resultados\n",
    "            ORGANISMO=Q.text # extrae unicamente los textos\n",
    "\n",
    "        #STATUS\n",
    "        status=soup.find_all(\"span\",class_='context-help bin-score tooltipped-click') # busca todos los elementos, con etiqueta span.\n",
    "        for Q in status: # limpia los resultados\n",
    "            STATUS_PRE=Q.text # extrae unicamente los textos\n",
    "        STATUS=STATUS_PRE.split(\"\\n\")[0].split(\":\")[1] # selecciona el status de toda esa respuesta\n",
    "\n",
    "        #GO BIOLOGICAL PROCESS\n",
    "        bio_process=soup.find_all(\"a\",onclick=\"window.ga('UniProt-Entry-View', 'click', 'Display-GO-Term');\") # busca todos los elementos, con etiqueta a\n",
    "        BIO_PROCESS=[] # crea una lista\n",
    "        for Q in bio_process: # limpia los resultados\n",
    "            BIO_PROCESS.append(Q.text) # selecciona los textos y los añade a la lista vacia\n",
    "        BIO_PROCESS=str(BIO_PROCESS) # vuelve toda la lista en una cadena \n",
    "         \n",
    "        \n",
    "        \n",
    "\n",
    "    except:                 # si es que no hay resultado en la busqueda dejara en blanco las celdas de los siguientes atributos\n",
    "        ENTRY=\"\"\n",
    "        ENTRY_NAME=\"\"\n",
    "        PROTEIN=\"\"\n",
    "        GEN_ABREV=\"\"\n",
    "        ORGANISMO=\"\"\n",
    "        STATUS=\"\"\n",
    "        BIO_PROCESS=\"\"\n",
    "        \n",
    "        excel=openpyxl.load_workbook('TablaVacia.xlsx') # abre el excel para completar los datos obtenidos en las columnas\n",
    "        sheet=excel['Hoja1']   # hoja 1 del excel\n",
    "        sheet.cell(row=m,column=3).value = ENTRY    # llena los valores \n",
    "        sheet.cell(row=m,column=4).value = ENTRY_NAME\n",
    "        sheet.cell(row=m,column=5).value = PROTEIN\n",
    "        sheet.cell(row=m,column=6).value = GEN_ABREV\n",
    "        sheet.cell(row=m,column=7).value = ORGANISMO\n",
    "        sheet.cell(row=m,column=8).value = STATUS\n",
    "        sheet.cell(row=m,column=9).value = BIO_PROCESS\n",
    "        excel.save('TablaVacia.xlsx')   # guarda el excel con los datos obtenidos  \n",
    "        m=m+1  # pasa a la siguiente fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
